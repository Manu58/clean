{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187ac604-4cdb-410d-ba56-d428e30376c6",
   "metadata": {},
   "source": [
    "We use polars to efficiently analyze the csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6654c1ab-2931-4b92-9ffb-28ba3bcb3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d9059-0b07-4553-ba4f-78478ed3501f",
   "metadata": {},
   "source": [
    "The parsed message will get the colukmn names as defined in the clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfc000f-1c59-4724-904d-e4f86a281fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGE_HEADERS = [\"status\", \"lat\", \"lat_dir\", \"lon\", \"lon_dir\", \"spd_over_grnd\", \"true_course\", \"datestamp\",\n",
    "                   \"mag_variation\", \"mag_var_dir\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e6568-619c-461b-89d7-e9df5cd67393",
   "metadata": {},
   "source": [
    "We next read the raw_messages.csv, split the raw message column and filter out all records that have a number of message parts not equal to \n",
    "```python\n",
    "len(MESSAGE_HEADERS)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a8b6e1-93c5-4b3f-93f9-19d97dba0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the csv file has shape (29052, 6)\n",
      "after separating the message details the shape is (29052, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_csv('raw_messages.csv', has_header=True)\n",
    "print(f' the csv file has shape {df.shape}')\n",
    "\n",
    "columns = df.columns[:-1]\n",
    "message = df.columns[-1]\n",
    "\n",
    "df = (df\n",
    "      .with_columns(pl.col(message).str.split(',').alias(message))\n",
    "      .filter(pl.col(message).list.lengths() == len(MESSAGE_HEADERS))  # nothing was filtered out\n",
    "      .with_columns(pl.col(message).list.to_struct())\n",
    "      .unnest(message)\n",
    "      .drop(message))\n",
    "df.columns = columns + MESSAGE_HEADERS\n",
    "print(f'after separating the message details the shape is {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9679372-15f3-4df3-97ab-1d6708b06841",
   "metadata": {},
   "source": [
    "looks good, apparently the number of parts of the message is correct for all entries. Now check if the numeric values are indeed numeric and the categorical entries have their predefined values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc0e4e0-cb73-4aae-ba7f-4ed9159c30c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20072, 15)\n"
     ]
    }
   ],
   "source": [
    "corrupt_df = (df\n",
    "      .filter(pl.col(\"status\").is_in([\"V\", \"A\"]))\n",
    "      .filter(pl.col(\"lat_dir\").is_in([\"N\", \"S\"]))\n",
    "      .filter(pl.col(\"lon_dir\").is_in([\"E\", \"W\"]))\n",
    "      .filter(pl.col(\"mag_var_dir\").is_in([\"E\", \"W\"]))\n",
    "      .filter(pl.col(\"lat\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"lon\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"spd_over_grnd\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"true_course\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"datestamp\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"mag_variation\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      )\n",
    "print(corrupt_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71730f0-91ba-428d-a681-80d37ae179ea",
   "metadata": {},
   "source": [
    "there are some records with errors in their message. We can filter all non desired characters out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "151abeed-f005-4824-a397-0a683fd21af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29052, 15)\n"
     ]
    }
   ],
   "source": [
    "final_df = (df\n",
    "      .with_columns(pl.col(\"status\").str.replace_all(r\"[^VA]\", \"\"))\n",
    "      .with_columns(pl.col(\"lon_dir\").str.replace_all(r\"[^EW]\", \"\"))\n",
    "      .with_columns(pl.col(\"lat_dir\").str.replace_all(r\"[^NS]\", \"\"))\n",
    "      .with_columns(pl.col(\"mag_var_dir\").str.replace_all(r\"[^EW]\", \"\"))\n",
    "      .with_columns(pl.col(\"lat\").str.replace_all(r\"[^0-9.]\", \"\"))\n",
    "      .with_columns(pl.col(\"lon\").str.replace_all(r\"[^0-9.]\", \"\"))\n",
    "      .with_columns(pl.col(\"lat\").str.replace_all(r\"[^0-9.]\", \"\"))\n",
    "      .with_columns(pl.col(\"spd_over_grnd\").str.replace_all(r\"[^0-9.]\", \"\"))\n",
    "      .with_columns(pl.col(\"true_course\").str.replace_all(r\"[^0-9.]\", \"\"))\n",
    "      .with_columns(pl.col(\"mag_variation\").str.replace_all(r\"[^0-9.]\", \"\"))\n",
    "      .filter(pl.col(\"status\").is_in([\"V\", \"A\"]))\n",
    "      .filter(pl.col(\"lat_dir\").is_in([\"N\", \"S\"]))\n",
    "      .filter(pl.col(\"lon_dir\").is_in([\"E\", \"W\"]))\n",
    "      .filter(pl.col(\"mag_var_dir\").is_in([\"E\", \"W\"]))\n",
    "      .filter(pl.col(\"lat\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"lon\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"spd_over_grnd\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"true_course\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"datestamp\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      .filter(pl.col(\"mag_variation\").str.contains(r'^\\d*\\.?\\d+'))\n",
    "      )\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fc412-aa98-41e9-8897-f80d1b5ffc82",
   "metadata": {},
   "source": [
    "that looks ok, there was just some noise in the messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "623342fd-67f2-493a-bee8-a02f19ac3fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (29_052, 15)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ device_id ┆ datetime  ┆ address_i ┆ address_p ┆ … ┆ true_cour ┆ datestamp ┆ mag_varia ┆ mag_var_ │\n",
      "│ ---       ┆ ---       ┆ p         ┆ ort       ┆   ┆ se        ┆ ---       ┆ tion      ┆ dir      │\n",
      "│ str       ┆ i64       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ str       ┆ ---       ┆ ---      │\n",
      "│           ┆           ┆ str       ┆ i64       ┆   ┆ str       ┆           ┆ str       ┆ str      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 0001      ┆ 155006699 ┆ 172.19.0. ┆ 4007      ┆ … ┆ 1.59      ┆ 150218    ┆ 0.8       ┆ E        │\n",
      "│           ┆ 9         ┆ 17        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 0001      ┆ 155006766 ┆ 172.19.0. ┆ 4007      ┆ … ┆ 1.59      ┆ 150218    ┆ 0.8       ┆ E        │\n",
      "│           ┆ 1         ┆ 16        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 0001      ┆ 155006704 ┆ 172.19.0. ┆ 4007      ┆ … ┆ 5.25      ┆ 150218    ┆ 0.8       ┆ E        │\n",
      "│           ┆ 8         ┆ 17        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 0001      ┆ 155006903 ┆ 172.19.0. ┆ 4007      ┆ … ┆ 5.25      ┆ 150218    ┆ 0.8       ┆ E        │\n",
      "│           ┆ 4         ┆ 16        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ st-1a2090 ┆ 155006006 ┆ 172.23.0. ┆ 4007      ┆ … ┆ 205.85    ┆ 130219    ┆ 1.4       ┆ E        │\n",
      "│           ┆ 1         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ st-1a2090 ┆ 155006006 ┆ 172.23.0. ┆ 4007      ┆ … ┆ 205.83    ┆ 130219    ┆ 1.4       ┆ E        │\n",
      "│           ┆ 2         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ st-1a2090 ┆ 155006006 ┆ 172.23.0. ┆ 4007      ┆ … ┆ 205.81    ┆ 130219    ┆ 1.4       ┆ E        │\n",
      "│           ┆ 3         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ st-1a2090 ┆ 155006006 ┆ 172.23.0. ┆ 4007      ┆ … ┆ 205.71    ┆ 130219    ┆ 1.4       ┆ E        │\n",
      "│           ┆ 3         ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "print(final_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d70b601c-28d5-4929-a97a-cb5671b56245",
   "metadata": {},
   "source": [
    "The datetime is in unix time we want it in human readable format.\n",
    "\n",
    "No need to convert the message columns to their actual data types, since we are exporting to csv  anyhow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1cc17d-0f96-4ce2-983b-c0d693e099be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write_csv('cleaned_messages.csv', has_header=True, datetime_format='%F %T')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
